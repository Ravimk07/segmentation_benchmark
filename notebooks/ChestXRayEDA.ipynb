{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from catalyst import dl, metrics, core, contrib, utils\n",
    "import torch.nn as nn\n",
    "from skimage.io import imread\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is EDA of Chest XRay dataset (https://www.kaggle.com/kmader/pulmonary-chest-xray-abnormalities/home?select=Montgomery + https://www.kaggle.com/yoctoman/shcxr-lung-mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_examples(images, masks, n_plot = 6):\n",
    "    f, ax = plt.subplots(n_plot, n_plot, figsize=(4*n_plot, 4*n_plot))\n",
    "    ax = ax.flatten()\n",
    "    idx_choice = np.random.choice(images.shape[0], size=n_plot**2)\n",
    "    for idx, idx_plot in enumerate(idx_choice):\n",
    "        image = imread(images[idx])\n",
    "        mask = imread(masks[idx])\n",
    "        ax[idx].imshow(image)\n",
    "        ax[idx].imshow(mask, alpha=0.5)\n",
    "        ax[idx].axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/data/personal_folders/skolchenko/segmentation_benchmark/ChestXray_prepared/masks/'\n",
    "masks_dir = '/data/personal_folders/skolchenko/segmentation_benchmark/ChestXray_prepared/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(images_dir)\n",
    "masks = np.array([masks_dir+image_path for image_path in images])\n",
    "images = np.array([images_dir+image_path for image_path in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_examples(images, masks, n_plot = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immediatly see that data is heterogeneous, with different provides, formats, scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "\n",
    "class ChestXRayDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        images,\n",
    "        masks,\n",
    "            transforms):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return(len(self.images))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Will load the mask, get random coordinates around/with the mask,\n",
    "        load the image by coordinates\n",
    "        \"\"\"\n",
    "        sample_image = imread(self.images[idx])\n",
    "        sample_image = np.expand_dims(sample_image, 2) / 255\n",
    "        sample_mask = imread(self.masks[idx]) / 255\n",
    "        augmented = self.transforms(image=sample_image, mask=sample_mask)\n",
    "        #augmented = self.transforms(image=sample_image)\n",
    "        sample_image = augmented['image']\n",
    "        sample_mask = augmented['mask']  \n",
    "        sample_image = sample_image.transpose(2, 0, 1)  # channels first\n",
    "        sample_mask = np.expand_dims(sample_mask, 0)\n",
    "        #sample_mask = sample_mask.transpose(2, 0, 1) \n",
    "\n",
    "        data = {'features': torch.from_numpy(sample_image.copy()).float(),\n",
    "                'mask': torch.from_numpy(sample_mask.copy())}\n",
    "        return(data)\n",
    "    \n",
    "def get_valid_transforms(crop_size=256):\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(crop_size, crop_size),\n",
    "        ],\n",
    "        p=1.0)\n",
    "\n",
    "def light_training_transforms(crop_size=256):\n",
    "    return A.Compose([\n",
    "        A.RandomResizedCrop(height=crop_size, width=crop_size),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.Transpose(),\n",
    "                A.VerticalFlip(),\n",
    "                A.HorizontalFlip(),\n",
    "                A.RandomRotate90(),\n",
    "                A.NoOp()\n",
    "            ], p=1.0),\n",
    "    ])\n",
    "\n",
    "def medium_training_transforms(crop_size=256):\n",
    "    return A.Compose([\n",
    "        A.RandomResizedCrop(height=crop_size, width=crop_size),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.Transpose(),\n",
    "                A.VerticalFlip(),\n",
    "                A.HorizontalFlip(),\n",
    "                A.RandomRotate90(),\n",
    "                A.NoOp()\n",
    "            ], p=1.0),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.CoarseDropout(max_holes=16, max_height=16, max_width=16),\n",
    "                A.NoOp()\n",
    "            ], p=1.0),\n",
    "    ])\n",
    "\n",
    "\n",
    "def heavy_training_transforms(crop_size=256):\n",
    "    return A.Compose([\n",
    "        A.RandomResizedCrop(height=crop_size, width=crop_size),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.Transpose(),\n",
    "                A.VerticalFlip(),\n",
    "                A.HorizontalFlip(),\n",
    "                A.RandomRotate90(),\n",
    "                A.NoOp()\n",
    "            ], p=1.0),\n",
    "        A.ShiftScaleRotate(p=0.75),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.CoarseDropout(max_holes=16, max_height=16, max_width=16),\n",
    "                A.NoOp()\n",
    "            ], p=1.0),\n",
    "    ])\n",
    "\n",
    "def get_training_trasnforms(transforms_type):\n",
    "    if transforms_type == 'light':\n",
    "        return(light_training_transforms())\n",
    "    elif transforms_type == 'medium':\n",
    "        return(medium_training_transforms())\n",
    "    elif transforms_type == 'heavy':\n",
    "        return(heavy_training_transforms())\n",
    "    else:\n",
    "        raise NotImplementedError(\"Not implemented transformation configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, images_valid, masks_train, masks_valid = train_test_split(images, masks, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ChestXRayDataset(images_train, masks_train, get_training_trasnforms('heavy'))\n",
    "val_dataset = ChestXRayDataset(images_valid, masks_valid, get_valid_transforms())\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=2, shuffle=True),\n",
    "    'valid': DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(loaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample['features'][0].cpu().numpy().transpose((1,2,0))[..., 0])\n",
    "plt.imshow(sample['mask'][0].cpu().numpy()[0], alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_toolbelt.losses import DiceLoss\n",
    "from pytorch_toolbelt.utils.catalyst import IoUMetricsCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.UnetPlusPlus('timm-regnety_004', classes=1, in_channels=1)\n",
    "#model.cuda()\n",
    "learning_rate = 5e-3\n",
    "encoder_learning_rate = 5e-3 / 10\n",
    "layerwise_params = {\"encoder*\": dict(lr=encoder_learning_rate, weight_decay=0.00003)}\n",
    "model_params = utils.process_model_params(model, layerwise_params=layerwise_params)\n",
    "base_optimizer = contrib.nn.RAdam(model_params, lr=learning_rate, weight_decay=0.0003)\n",
    "optimizer = contrib.nn.Lookahead(base_optimizer)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.25, patience=10)\n",
    "criterion = {\n",
    "    \"dice\": DiceLoss(mode='binary'),\n",
    "    \"bce\": nn.BCEWithLogitsLoss()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.dl import  CriterionCallback, MetricAggregationCallback\n",
    "\n",
    "callbacks = [\n",
    "    # Each criterion is calculated separately.\n",
    "    CriterionCallback(\n",
    "       input_key=\"mask\",\n",
    "        prefix=\"loss_dice\",\n",
    "        criterion_key=\"dice\"\n",
    "    ),\n",
    "    CriterionCallback(\n",
    "        input_key=\"mask\",\n",
    "        prefix=\"loss_bce\",\n",
    "        criterion_key=\"bce\"\n",
    "    ),\n",
    "\n",
    "    # And only then we aggregate everything into one loss.\n",
    "    MetricAggregationCallback(\n",
    "        prefix=\"loss\",\n",
    "        mode=\"weighted_sum\", \n",
    "        metrics={\n",
    "            \"loss_dice\": 1.0, \n",
    "            \"loss_bce\": 0.8\n",
    "        },\n",
    "    ),\n",
    "\n",
    "    # metrics\n",
    "    IoUMetricsCallback(\n",
    "        mode='binary', \n",
    "        input_key='mask', \n",
    "    )\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = dl.SupervisedRunner(input_key=\"features\", input_target_key=\"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    callbacks=callbacks,\n",
    "    logdir='../logs/initial_test_xray',\n",
    "    num_epochs=100,\n",
    "    main_metric=\"loss\",\n",
    "    minimize_metric=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation_models",
   "language": "python",
   "name": "segmentation_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
